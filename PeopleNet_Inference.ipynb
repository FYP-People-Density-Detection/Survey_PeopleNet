{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12402ab-a627-4213-bf09-b09f96e26cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, traceback\n",
    "import pycuda.driver as cuda\n",
    "from copy import deepcopy\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class NMS(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_iou(bb1, bb2):\n",
    "        \"\"\"\n",
    "        Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bb1 : dict\n",
    "            Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "            The (x1, y1) position is at the top left corner,\n",
    "            the (x2, y2) position is at the bottom right corner\n",
    "        bb2 : dict\n",
    "            Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "            The (x, y) position is at the top left corner,\n",
    "            the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            in [0, 1]\n",
    "        \"\"\"\n",
    "        left1,top1,right1,bottom1 = bb1\n",
    "        left2,top2,right2,bottom2 = bb2\n",
    "\n",
    "        # determine the coordinates of the intersection rectangle\n",
    "        x_left = max(left1, left2)\n",
    "        y_top = max(top1, top2)\n",
    "        x_right = min(right1, right2)\n",
    "        y_bottom = min(bottom1, bottom2)\n",
    "\n",
    "        if x_right < x_left or y_bottom < y_top:\n",
    "            return 0.0\n",
    "\n",
    "        # The intersection of two axis-aligned bounding boxes is always an\n",
    "        # axis-aligned bounding box\n",
    "        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "        # compute the area of both AABBs\n",
    "        bb1_area = (right1 - left1) * (bottom1 - top1)\n",
    "        bb2_area = (right2 - right1) * (bottom2 - top2)\n",
    "\n",
    "        # compute the intersection over union by taking the intersection\n",
    "        # area and dividing it by the sum of prediction + ground-truth\n",
    "        # areas - the interesection area\n",
    "        iou = 0.0\n",
    "        if(bb1_area + bb2_area - intersection_area) == 0.0:\n",
    "            iou = 1.0\n",
    "        else:\n",
    "            iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    @staticmethod\n",
    "    def filter(rects):\n",
    "        results = []\n",
    "        rids = []\n",
    "\n",
    "        for rid,rect in enumerate(rects):\n",
    "            rids.append(rid)\n",
    "\n",
    "        del_rids = []\n",
    "        scores = []  #  仅仅为了debug使用\n",
    "        for i_rid in rids:\n",
    "            for j_rid in rids:\n",
    "                if j_rid <= i_rid:\n",
    "                    continue\n",
    "\n",
    "                bbx_i = rects[i_rid]\n",
    "                bbx_j = rects[j_rid]\n",
    "\n",
    "                iou = NMS.get_iou(bbx_i, bbx_j)\n",
    "\n",
    "                score = i_rid,j_rid,iou\n",
    "                if iou >= 0.9:\n",
    "                    del_rids.append(j_rid)\n",
    "                scores.append(score)\n",
    "\n",
    "        for rid,rect in enumerate(rects):\n",
    "            if int(rid) not in del_rids:\n",
    "                results.append(rect)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "class PeopleNetPostProcess(object):\n",
    "\n",
    "    def __init__(self, width, height, score=0.5, classes=[0]):\n",
    "        '''\n",
    "        Params:\n",
    "            width,height(int) is the image-size that you want to get the BBX\n",
    "            score(float) is the confidence\n",
    "            classes(int-list) is the 3-classes(0 for person,1 for bag, 2 for face)\n",
    "        '''\n",
    "        self.image_width = width\n",
    "        self.image_height = height\n",
    "\n",
    "        self.model_h = 544\n",
    "        self.model_w = 960\n",
    "        self.stride = 16.0\n",
    "        self.box_norm = 35.0\n",
    "\n",
    "        self.grid_h = int(self.model_h / self.stride)\n",
    "        self.grid_w = int(self.model_w / self.stride)\n",
    "        self.grid_size = self.grid_h * self.grid_w\n",
    "\n",
    "        self.grid_centers_w = []\n",
    "        self.grid_centers_h = []\n",
    "\n",
    "        for i in range(self.grid_h):\n",
    "            value = (i * self.stride + 0.5) / self.box_norm\n",
    "            self.grid_centers_h.append(value)\n",
    "\n",
    "        for i in range(self.grid_w):\n",
    "            value = (i * self.stride + 0.5) / self.box_norm\n",
    "            self.grid_centers_w.append(value)\n",
    "\n",
    "        '''\n",
    "        min_confidence (float): min confidence to accept detection\n",
    "        analysis_classes (list of int): indices of the classes to consider\n",
    "        '''\n",
    "        self.min_confidence = score\n",
    "        self.analysis_classes = classes\n",
    "\n",
    "    def applyBoxNorm(self, o1, o2, o3, o4, x, y):\n",
    "        \"\"\"\n",
    "        Applies the GridNet box normalization\n",
    "        Args:\n",
    "            o1 (float): first argument of the result\n",
    "            o2 (float): second argument of the result\n",
    "            o3 (float): third argument of the result\n",
    "            o4 (float): fourth argument of the result\n",
    "            x: row index on the grid\n",
    "            y: column index on the grid\n",
    "\n",
    "        Returns:\n",
    "            float: rescaled first argument\n",
    "            float: rescaled second argument\n",
    "            float: rescaled third argument\n",
    "            float: rescaled fourth argument\n",
    "        \"\"\"\n",
    "        o1 = (o1 - self.grid_centers_w[x]) * -self.box_norm\n",
    "        o2 = (o2 - self.grid_centers_h[y]) * -self.box_norm\n",
    "        o3 = (o3 + self.grid_centers_w[x]) * self.box_norm\n",
    "        o4 = (o4 + self.grid_centers_h[y]) * self.box_norm\n",
    "        return o1, o2, o3, o4\n",
    "\n",
    "    def change_model_size_to_real(self, model_size, type):\n",
    "        real_size = 0\n",
    "        if type == 'x':\n",
    "            real_size = (model_size / float(self.model_w)) * self.image_width\n",
    "        elif type == 'y':\n",
    "            real_size = (model_size / float(self.model_h)) * self.image_height\n",
    "        real_size = int(real_size)\n",
    "        return real_size\n",
    "\n",
    "    def start(self, buffer_bbox, buffer_scores):\n",
    "        \"\"\"\n",
    "        Postprocesses the inference output\n",
    "        Args:\n",
    "            outputs (list of float): inference output\n",
    "        Returns: list of list tuple: each element is a two list tuple (x, y) representing the corners of a bb\n",
    "        \"\"\"\n",
    "\n",
    "        bbs = []\n",
    "        for c in range(3):\n",
    "            if c not in self.analysis_classes:\n",
    "                continue\n",
    "\n",
    "            x1_idx = (c * 4 * self.grid_size)\n",
    "            y1_idx = x1_idx + self.grid_size\n",
    "            x2_idx = y1_idx + self.grid_size\n",
    "            y2_idx = x2_idx + self.grid_size\n",
    "\n",
    "            boxes = buffer_bbox\n",
    "            for h in range(self.grid_h):\n",
    "                for w in range(self.grid_w):\n",
    "                    i = w + h * self.grid_w\n",
    "                    score = buffer_scores[c * self.grid_size + i]\n",
    "                    if score >= self.min_confidence:\n",
    "                        o1 = boxes[x1_idx + w + h * self.grid_w]\n",
    "                        o2 = boxes[y1_idx + w + h * self.grid_w]\n",
    "                        o3 = boxes[x2_idx + w + h * self.grid_w]\n",
    "                        o4 = boxes[y2_idx + w + h * self.grid_w]\n",
    "\n",
    "                        o1, o2, o3, o4 = self.applyBoxNorm(o1, o2, o3, o4, w, h)\n",
    "\n",
    "                        xmin_model = int(o1)\n",
    "                        ymin_model = int(o2)\n",
    "                        xmax_model = int(o3)\n",
    "                        ymax_model = int(o4)\n",
    "\n",
    "                        xmin_image = self.change_model_size_to_real(xmin_model, 'x')\n",
    "                        ymin_image = self.change_model_size_to_real(ymin_model, 'y')\n",
    "                        xmax_image = self.change_model_size_to_real(xmax_model, 'x')\n",
    "                        ymax_image = self.change_model_size_to_real(ymax_model, 'y')\n",
    "\n",
    "                        rect = (xmin_image, ymin_image, xmax_image, ymax_image)\n",
    "\n",
    "                        bbs.append(rect)\n",
    "        return bbs\n",
    "\n",
    "\n",
    "class PeopleNetTRTInference(object):\n",
    "\n",
    "    def __init__(self, width, height, model_path='models/resnet34_peoplenet_fp16.engine',warm_up=True):\n",
    "        self.dtype = trt.float32\n",
    "        self.width = 960\n",
    "        self.height = 544\n",
    "        self.channel = 3\n",
    "\n",
    "        logger = trt.Logger()\n",
    "        runtime = trt.Runtime(logger)\n",
    "        with open(model_path, 'rb') as file:\n",
    "            engine = runtime.deserialize_cuda_engine(file.read())\n",
    "\n",
    "        self.context = engine.create_execution_context()\n",
    "\n",
    "        self.host_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)),\n",
    "                                                dtype=trt.nptype(self.dtype))\n",
    "\n",
    "        #  BBox\n",
    "        self.host_output_0 = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)),\n",
    "                                                   dtype=trt.nptype(self.dtype))\n",
    "        #  Confidence\n",
    "        self.host_output_1 = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(2)),\n",
    "                                                   dtype=trt.nptype(self.dtype))\n",
    "\n",
    "        self.device_input = cuda.mem_alloc(self.host_input.nbytes)\n",
    "        self.device_output_0 = cuda.mem_alloc(self.host_output_0.nbytes)\n",
    "        self.device_output_1 = cuda.mem_alloc(self.host_output_1.nbytes)\n",
    "\n",
    "        self.stream = cuda.Stream()\n",
    "\n",
    "        self.post_process = PeopleNetPostProcess(width, height)\n",
    "\n",
    "        if warm_up:\n",
    "            self.warm_up()\n",
    "\n",
    "    def start(self, raw):\n",
    "        image = deepcopy(raw)\n",
    "        image = cv2.resize(image, (self.width, self.height))\n",
    "\n",
    "        img_array = np.asarray(image).astype(trt.nptype(self.dtype))  # .ravel()\n",
    "        img_array = img_array.transpose(2, 0, 1) / 255.0\n",
    "        img_array = img_array.ravel()\n",
    "        np.copyto(self.host_input, img_array)\n",
    "\n",
    "        #\n",
    "        # Transfer input data to the GPU.\n",
    "        #\n",
    "        cuda.memcpy_htod_async(self.device_input, self.host_input, self.stream)\n",
    "\n",
    "        ret = self.context.execute_async(batch_size=1, bindings=[int(self.device_input), int(self.device_output_0),\n",
    "                                                                 int(self.device_output_1)],\n",
    "                                         stream_handle=self.stream.handle)\n",
    "\n",
    "        # Transfer predictions back from the GPU.\n",
    "        cuda.memcpy_dtoh_async(self.host_output_0, self.device_output_0, self.stream)\n",
    "        cuda.memcpy_dtoh_async(self.host_output_1, self.device_output_1, self.stream)\n",
    "\n",
    "        self.stream.synchronize()\n",
    "\n",
    "        rects = self.post_process.start(self.host_output_0, self.host_output_1)\n",
    "        rects = NMS.filter(rects)\n",
    "        return rects\n",
    "\n",
    "    def warm_up(self):\n",
    "\n",
    "        print('Start Warm-up.')\n",
    "        for i in range(10):\n",
    "            image = np.random.randint(0, 255, size=(300, 300, 3), dtype=np.uint8)\n",
    "            self.start(image)\n",
    "        print('Stop Warm-up.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2ee99d-76a8-4366-af5a-2f1d0a0e55d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Warm-up.\n",
      "Stop Warm-up.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    pp = PeopleNetTRTInference(960, 544, 'models/resnet34_peoplenet_fp16.engine')\n",
    "\n",
    "    image = cv2.imread('output_images/output_544_960.jpg')\n",
    "    rects = pp.start(image)\n",
    "\n",
    "    for rect in rects:\n",
    "        left, top, right, bottom = rect\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imwrite('images/output.jpg', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3bdf5b-e0d5-4b09-bc3a-24b2fa3420dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Warm-up.\n",
      "Stop Warm-up.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pp = PeopleNetTRTInference(960, 544, 'models/resnet34_peoplenet_fp16.engine')\n",
    "directory = 'output_images'\n",
    "fw = open(\"inference_images/logs.txt\", \"w\")\n",
    "\n",
    "smallest_rect = 10000\n",
    "for filename in os.listdir(directory):\n",
    "    path = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(path):\n",
    "        fw.writelines(f'-----------------Processing {filename}-------------------------\\n')\n",
    "        res = os.path.splitext(filename)[0].split('_')\n",
    "        height, width = res[1], res[2]\n",
    "        image = cv2.imread(path)\n",
    "        rects = pp.start(image)\n",
    "\n",
    "        num_rect = 0\n",
    "        for rect in rects:\n",
    "            left, top, right, bottom = rect\n",
    "            area = (right-left)*(bottom-top)\n",
    "            smallest_rect = min(smallest_rect, area)\n",
    "            fw.writelines(f'Rect {num_rect} (left, top, right, bottom): ({left}, {top}, {right}, {bottom}), Area: {area}\\n')\n",
    "            cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            num_rect +=1\n",
    "\n",
    "        cv2.imwrite(f'inference_images/inferenced_{height}_{width}.jpg', image)\n",
    "        fw.writelines(f'-----------------Done {filename}-------------------------\\n')\n",
    "\n",
    "fw.writelines(f'Smallest Area: {smallest_rect}\\n')\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd40f7-8230-4b09-b142-57fd9d12d517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
